import os
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
import requests
from pydub import AudioSegment

user_profiles = {}
user_states = {}
user_histories = {}
user_topics = {}

survey_questions = [
    ("native", "ğŸ—£ ëª¨êµ­ì–´ê°€ ë¬´ì—‡ì¸ê°€ìš”? (Your native language)?"),
    ("target", "ğŸ“˜ ë°°ìš°ê³  ì‹¶ì€ ì–¸ì–´ëŠ” ë¬´ì—‡ì¸ê°€ìš”? (Which language would you like to learn?)"),
    ("age", "ğŸ“… ë‚˜ì´ëŒ€ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”? (What is your age group?)"),
    ("gender", "ğŸ‘¤ ì„±ë³„ì´ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”? (ë‚¨ì„±/ì—¬ì„±)"),
    ("level", "ğŸ“Š í˜„ì¬ ì‹¤ë ¥ì€ ì–´ëŠì •ë„ì¸ê°€ìš”? (Your level: beginner/intermediate?)")
]

language_explanation = {
    "Korean": "ì„¤ëª…ì€ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.",
    "Japanese": "èª¬æ˜ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚",
    "Spanish": "Explica en espaÃ±ol, por favor.",
    "Vietnamese": "Giáº£i thÃ­ch báº±ng tiáº¿ng Viá»‡t giÃºp tÃ´i.",
    "Chinese": "è¯·ç”¨ä¸­æ–‡è§£é‡Šã€‚",
    "Indonesian": "Tolong jelaskan dalam Bahasa Indonesia."
}

def get_system_prompt(profile):  # ğŸ’¡ Modified to reflect level-based instruction language handling
    explanation = language_explanation.get(profile['native'], "Explain in English.")
    level = profile.get("level", "beginner").lower()

    if "ì¤‘ê¸‰" in level or "intermediate" in level:
        return f"""
You are a GPT-based smart English tutor.
Speak very slowly and clearly. The learner is beginner level.
Use {profile['native']} to explain most of the content and instructions, but provide all English examples and practice in {profile['target']}.
Deliver all practice content in {profile['target']} and provide supportive explanation in {profile['native']} when necessary to aid understanding.
When a topic is given (e.g., travel, computer), break it into subtopics.
For each example sentence:
- Provide the English sentence.
- Translate it into the learner's native language.
- Explain key vocabulary with meaning in the native language.
- Ask the learner to repeat the sentence aloud.
- After listening, give pronunciation and grammar feedback.
After the learner finishes 3-4 sentences, ask them a question that allows them to use the learned expressions in a short, creative response. Guide the learner to practice and build confidence.
Make it interactive and guide them step-by-step.
"""

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_states[user_id] = 0
    user_profiles[user_id] = {}
    await update.message.reply_text("ğŸ‘‹ ì„¤ë¬¸ì„ ì‹œì‘í•©ë‹ˆë‹¤! Let's start the survey!")
    await ask_next_question(update, user_id)

async def ask_next_question(update, user_id):
    state = user_states[user_id]
    if state < len(survey_questions):
        key, question = survey_questions[state]
        await update.message.reply_text(question)
    else:
        await update.message.reply_text("âœ… ì„¤ë¬¸ ì™„ë£Œ! ì´ì œ ìˆ˜ì—…ì„ ì‹œì‘í• ê²Œìš” í˜•ë‹˜.")
        del user_states[user_id]
        await update.message.reply_text("ë¬´ìŠ¨ ì£¼ì œë¡œ ìˆ˜ì—…ì„ ì‹œì‘í•´ë³¼ê¹Œìš”?")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    text = update.message.text.strip()

    if user_id in user_states:
        state = user_states[user_id]
        key, _ = survey_questions[state]
        user_profiles[user_id][key] = text
        user_states[user_id] += 1
        await ask_next_question(update, user_id)
    else:
        profile = user_profiles.get(user_id)
        if profile:
            await tutor_response(text, update, profile)
        else:
            # Check if user has already completed the survey
            if user_id not in user_profiles or not user_profiles[user_id].get("level"):
                await update.message.reply_text("ì²˜ìŒ ì˜¤ì…¨êµ°ìš”! ì„¤ë¬¸ë¶€í„° ì§„í–‰í• ê²Œìš” í˜•ë‹˜ ğŸ“")
                user_states[user_id] = 0
                user_profiles[user_id] = {}
                await ask_next_question(update, user_id)
            else:
                await tutor_response(text, update, user_profiles[user_id])

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if user_id not in user_profiles:
        await update.message.reply_text("ì²˜ìŒ ì˜¤ì…¨êµ°ìš”! ì„¤ë¬¸ë¶€í„° ì§„í–‰í• ê²Œìš” í˜•ë‹˜ ğŸ“")
        user_states[user_id] = 0
        user_profiles[user_id] = {}
        await ask_next_question(update, user_id)
        return

    file = await context.bot.get_file(update.message.voice.file_id)
    ogg_path = "voice.ogg"
    mp3_path = "voice.mp3"
    await file.download_to_drive(ogg_path)
    AudioSegment.from_ogg(ogg_path).export(mp3_path, format="mp3")

    with open(mp3_path, "rb") as f:
        transcript = openai.audio.transcriptions.create(model="whisper-1", file=f)

    await tutor_response(transcript.text, update, user_profiles[user_id])

async def tutor_response(user_input: str, update: Update, profile: dict):
    try:
        user_id = update.effective_user.id
        system_prompt = get_system_prompt(profile)
        if not system_prompt or not isinstance(system_prompt, str):
            system_prompt = "You are a helpful tutor. Please guide the learner step-by-step."

        if user_id not in user_histories:
            user_histories[user_id] = []

        if user_id not in user_topics:
            user_topics[user_id] = None

        # ì£¼ì œë¥¼ ì²˜ìŒ ì •í–ˆì„ ê²½ìš° ì €ì¥
        if user_topics[user_id] is None:
            user_topics[user_id] = user_input
            user_topics[user_id] = user_input

        user_histories[user_id].append({"role": "user", "content": user_input})
        history = [msg for msg in user_histories[user_id][-10:] if msg.get("content")]
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Please start an English lesson using the topic '{user_topics[user_id]}' and provide practice in {profile['target']}, with explanations in {profile['native']}."}
        ] + history

        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages
        )

        reply = response.choices[0].message.content
        user_histories[user_id].append({"role": "assistant", "content": reply})

        await update.message.reply_text(reply)

        speech = openai.audio.speech.create(
            model="tts-1",
            voice="nova",
            input=reply
        )
        tts_path = "response.mp3"
        with open(tts_path, "wb") as f:
            f.write(speech.content)

        await update.message.reply_voice(voice=open(tts_path, "rb"))

    except Exception as e:
        await update.message.reply_text(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    openai.api_key = os.getenv("OPENAI_API_KEY")
    app = ApplicationBuilder().token(os.getenv("TELEGRAM_TOKEN")).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    print("âœ… CC4AI íŠœí„° ì‘ë™ ì¤‘")
    app.run_polling()
