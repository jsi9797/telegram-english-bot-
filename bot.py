import os
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
from pydub import AudioSegment

user_profiles = {}
user_states = {}
user_histories = {}
user_topics = {}
user_vocab = {}
user_vocab_done = {}
user_sentences = {}
user_sent_idx = {}

survey_questions = [
    ("native", "ğŸ—£ ëª¨êµ­ì–´ê°€ ë¬´ì—‡ì¸ê°€ìš”? (Your native language)?"),
    ("target", "ğŸ“˜ ë°°ìš°ê³  ì‹¶ì€ ì–¸ì–´ëŠ” ë¬´ì—‡ì¸ê°€ìš”? (Which language would you like to learn?)"),
    ("age", "ğŸ“… ë‚˜ì´ëŒ€ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”? (What is your age group?)"),
    ("gender", "ğŸ‘¤ ì„±ë³„ì´ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”? (ë‚¨ì„±/ì—¬ì„±)"),
    ("level", "ğŸ“Š í˜„ì¬ ì‹¤ë ¥ì€ ì–´ëŠì •ë„ì¸ê°€ìš”? (Your level: beginner/intermediate?)")
]

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_states[user_id] = 0
    user_profiles[user_id] = {}
    await update.message.reply_text("ğŸ‘‹ ì„¤ë¬¸ì„ ì‹œì‘í•©ë‹ˆë‹¤! Let's start the survey!")
    await ask_next_question(update, user_id)

async def ask_next_question(update, user_id):
    state = user_states[user_id]
    if state < len(survey_questions):
        key, question = survey_questions[state]
        await update.message.reply_text(question)
    else:
        await update.message.reply_text("âœ… ì„¤ë¬¸ ì™„ë£Œ! ì´ì œ ìˆ˜ì—…ì„ ì‹œì‘í• ê²Œìš”.")
        del user_states[user_id]
        await update.message.reply_text("ë¬´ìŠ¨ ì£¼ì œë¡œ ìˆ˜ì—…ì„ ì‹œì‘í•´ë³¼ê¹Œìš”?")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    text = update.message.text.strip()

    if user_id not in user_profiles or "level" not in user_profiles[user_id]:
        if user_id not in user_states:
            user_states[user_id] = 0
            user_profiles[user_id] = {}
            await update.message.reply_text("ğŸ‘‹ ì„¤ë¬¸ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
        state = user_states[user_id]
        key, _ = survey_questions[state]
        user_profiles[user_id][key] = text
        user_states[user_id] += 1
        await ask_next_question(update, user_id)
        return

    if user_id not in user_topics:
        user_topics[user_id] = text
        # ì˜ˆì‹œ ë‹¨ì–´ì™€ ë¬¸ì¥ (í•˜ë“œì½”ë”©ëœ ì˜ˆì‹œ)
        vocab_list = ["computer", "keyboard", "monitor", "mouse", "internet"]
        sentences = [
            "I use my computer to browse the internet.",
            "The monitor is very bright.",
            "I need a new keyboard for work."
        ]
        user_vocab[user_id] = vocab_list
        user_sentences[user_id] = sentences
        user_sent_idx[user_id] = 0
        user_vocab_done[user_id] = False
        await update.message.reply_text("ì¢‹ì•„ìš”. ë‹¨ì–´ë“¤ì„ í•˜ë‚˜ì”© ë”°ë¼ ë§í•´ë³¼ê¹Œìš”?\n")
        for idx, word in enumerate(vocab_list, 1):
            await update.message.reply_text(f"{idx}. {word}")
        await update.message.reply_text("âœï¸ ìœ„ ë‹¨ì–´ë“¤ì„ í•œë²ˆì”© ë”°ë¼ ë§í•´ë³´ê³ , ì¤€ë¹„ê°€ ë˜ë©´ ë…¹ìŒí•˜ì—¬ ì „ì†¡í•´ì£¼ì„¸ìš”!")
        return

    await update.message.reply_text("âœ‹ ìŒì„±ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ë”°ë¼ ë§í•´ì£¼ì‹œê³ , ë°œìŒ í”¼ë“œë°±ì„ ë°›ìœ¼ë©´ ë¬¸ì¥ í•™ìŠµìœ¼ë¡œ ë„˜ì–´ê°€ìš”!")

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if user_id not in user_profiles or user_id not in user_topics:
        await update.message.reply_text("ë¨¼ì € ì„¤ë¬¸ì„ ì™„ë£Œí•˜ê³  ìˆ˜ì—… ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    file = await context.bot.get_file(update.message.voice.file_id)
    ogg_path = "voice.ogg"
    mp3_path = "voice.mp3"
    await file.download_to_drive(ogg_path)
    AudioSegment.from_ogg(ogg_path).export(mp3_path, format="mp3")

    with open(mp3_path, "rb") as f:
        transcript = openai.audio.transcriptions.create(model="whisper-1", file=f)

    text = transcript.text.strip()
    await update.message.reply_text(f"ğŸ§ ì¸ì‹ëœ ë°œí™”: {text}")

    # ë°œìŒ í”¼ë“œë°± ìš”ì²­
    feedback = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a strict pronunciation coach. Give honest feedback on each word's clarity."},
            {"role": "user", "content": f"The learner said: '{text}'. Please give feedback on each word."}
        ]
    ).choices[0].message.content

    await update.message.reply_text(f"ğŸ—£ï¸ ë°œìŒ í”¼ë“œë°±:\n{feedback}")

    # ë‹¨ì–´ í•™ìŠµ ì™„ë£Œ ì—¬ë¶€
    if not user_vocab_done[user_id]:
        user_vocab_done[user_id] = True
        await update.message.reply_text("âœ… ë‹¨ì–´ í•™ìŠµì„ ë§ˆì³¤ì–´ìš”. ì´ì œ ë¬¸ì¥ í•™ìŠµìœ¼ë¡œ ë„˜ì–´ê°ˆê²Œìš”.")
        await send_next_sentence(update, user_id)
        return

    # ë¬¸ì¥ í•™ìŠµ
    await update.message.reply_text("ì˜ ë“¤ì—ˆì–´ìš”! ê³„ì†í•´ì„œ ë¬¸ì¥ í•™ìŠµì„ ì´ì–´ê°ˆê²Œìš”.")
    await send_next_sentence(update, user_id)

async def send_next_sentence(update, user_id):
    idx = user_sent_idx[user_id]
    sentences = user_sentences[user_id]
    if idx >= len(sentences):
        await update.message.reply_text("ğŸ‰ ëª¨ë“  ë¬¸ì¥ì„ ì™„ë£Œí–ˆì–´ìš”! ì´ì œ ë°°ìš´ ë¬¸ì¥ì„ ì‘ìš©í•´ë³¼ê¹Œìš”?")
        return
    sentence = sentences[idx]
    await update.message.reply_text(f"{idx+1}. {sentence}\nì´ ë¬¸ì¥ì„ í•œë²ˆ ë”°ë¼ ë§í•´ë³´ê³ , ì¤€ë¹„ê°€ ë˜ë©´ ë…¹ìŒí•˜ì—¬ ì „ì†¡í•´ì£¼ì„¸ìš”!")
    user_sent_idx[user_id] += 1

if __name__ == "__main__":
    openai.api_key = os.getenv("OPENAI_API_KEY")
    app = ApplicationBuilder().token(os.getenv("TELEGRAM_TOKEN")).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    print("âœ… CC4AI íŠœí„° ì‘ë™ ì¤‘")
    app.run_polling()
