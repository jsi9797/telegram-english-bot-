import os
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
import requests
from pydub import AudioSegment

openai.api_key = os.getenv("OPENAI_API_KEY")

# ì‚¬ìš©ìë³„ ìƒíƒœ ì €ì¥
user_states = {}
user_profiles = {}
user_languages = {}

# ì–¸ì–´ë³„ ì•ˆë‚´ ë©”ì‹œì§€
survey_questions = [
    ("company", "âœ… íšŒì‚¬ëª… (Your company name)?"),
    ("teacher", "âœ… ê°•ì‚¬ ì´ë¦„ (Your teacher's name)?"),
    ("native_language", "âœ… ëª¨êµ­ì–´ê°€ ë¬´ì—‡ì¸ê°€ìš”? (Your native language?)"),
    ("target_language", "âœ… ë°°ìš°ê³  ì‹¶ì€ ì–¸ì–´ëŠ” ë¬´ì—‡ì¸ê°€ìš”? (Which language would you like to learn?)"),
    ("age_group", "âœ… ë‚˜ì´ëŒ€ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”? (What is your age group?)"),
    ("level", "âœ… í˜„ì¬ ì‹¤ë ¥ì€ ì–´ëŠì •ë„ì¸ê°€ìš”? (ì˜ˆ: ì´ˆê¸‰, ì¤‘ê¸‰, ê³ ê¸‰ ë˜ëŠ” ì„¤ëª…ìœ¼ë¡œ)\n(What's your level? e.g. beginner, intermediate, advanced or describe it)")
]

language_prompt = """
ğŸŒ Please choose your explanation language / ì„¤ëª…ì„ ì›í•˜ëŠ” ì–¸ì–´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:

ğŸ‡°ğŸ‡· Korean
ğŸ‡¯ğŸ‡µ Japanese
ğŸ‡¨ğŸ‡³ Chinese
ğŸ‡ªğŸ‡¸ Spanish
ğŸ‡»ğŸ‡³ Vietnamese
ğŸ‡®ğŸ‡© Indonesian
ğŸ‡ºğŸ‡¸ English (default)
"""

def get_system_prompt(language):
    explanation = {
        "Korean": "ì„¤ëª…ì€ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.",
        "Japanese": "èª¬æ˜ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚",
        "Spanish": "Explica en espaÃ±ol, por favor.",
        "Vietnamese": "Giáº£i thÃ­ch báº±ng tiáº¿ng Viá»‡t giÃºp tÃ´i.",
        "Chinese": "è¯·ç”¨ä¸­æ–‡è§£é‡Šã€‚",
        "Indonesian": "Tolong jelaskan dalam Bahasa Indonesia."
    }.get(language, "Explain in English.")

    return f"""
You are a friendly and professional language tutor.
When the student says things like 'Let's start' or 'Teach me',
you start a mini-lesson with useful daily expressions and short dialogue practice.
Correct their grammar and pronunciation kindly and provide encouragement.
{explanation}
Always keep your tone kind, simple, and supportive.
"""

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_states[user_id] = {"step": 0, "answers": {}}
    await update.message.reply_text("ğŸ‘‹ ì„¤ë¬¸ì„ ì‹œì‘í•©ë‹ˆë‹¤!\nLet's start the survey!")
    await update.message.reply_text(survey_questions[0][1])

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    text = update.message.text.strip()

    if user_id not in user_states:
        await update.message.reply_text("/start ëª…ë ¹ì–´ë¡œ ì„¤ë¬¸ì„ ë¨¼ì € ì‹œì‘í•´ì£¼ì„¸ìš”. Please type /start to begin.")
        return

    await handle_survey_step(user_id, text, update)

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id

    file = await context.bot.get_file(update.message.voice.file_id)
    ogg_path = "voice.ogg"
    mp3_path = "voice.mp3"
    await file.download_to_drive(ogg_path)
    AudioSegment.from_ogg(ogg_path).export(mp3_path, format="mp3")

    with open(mp3_path, "rb") as f:
        transcript = openai.audio.transcriptions.create(
            model="whisper-1",
            file=f
        )
    user_text = transcript.text

    if user_id in user_states:
        await handle_survey_step(user_id, user_text, update)
    elif user_id in user_profiles:
        await tutor_response(user_text, update, user_languages.get(user_id, "English"))
    else:
        await update.message.reply_text("/startë¡œ ì„¤ë¬¸ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”. Please complete the survey with /start first.")

async def handle_survey_step(user_id, text, update):
    state = user_states[user_id]
    step = state["step"]
    state["answers"][survey_questions[step][0]] = text
    state["step"] += 1

    if state["step"] < len(survey_questions):
        await update.message.reply_text(survey_questions[state["step"]][1])
    else:
        user_profiles[user_id] = state["answers"]
        user_languages[user_id] = user_profiles[user_id].get("native_language", "English")
        del user_states[user_id]
        await update.message.reply_text("âœ… ì„¤ë¬¸ ì™„ë£Œ! ìˆ˜ì—…ì„ ì‹œì‘í• ê²Œìš”.\nSurvey complete! Let's begin the lesson.")
        await tutor_response("ìˆ˜ì—… ì‹œì‘", update, user_languages[user_id])

async def tutor_response(user_input: str, update: Update, language: str):
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": get_system_prompt(language)},
                {"role": "user", "content": user_input}
            ]
        )
        reply = response.choices[0].message.content
        await update.message.reply_text(reply)

        speech = openai.audio.speech.create(
            model="tts-1",
            voice="nova",
            input=reply
        )
        tts_path = "response.mp3"
        with open(tts_path, "wb") as f:
            f.write(speech.content)

        await update.message.reply_voice(voice=open(tts_path, "rb"))

    except Exception as e:
        await update.message.reply_text(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    app = ApplicationBuilder().token(os.getenv("TELEGRAM_TOKEN")).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))

    print("âœ… CC4AI Tutor with Survey + Voice Input is running")
    app.run_polling()
