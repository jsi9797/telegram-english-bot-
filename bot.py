import os
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
import requests
from pydub import AudioSegment

openai.api_key = os.getenv("OPENAI_API_KEY")

# /start ëª…ë ¹
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ™ ìŒì„± ë˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ êµì •í•´ë“œë¦´ê²Œìš”!")

# í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
async def correct_english_and_respond(user_input: str, update: Update):
    prompt = f"Correct this English sentence and explain briefly:\n\n\"{user_input}\""
    try:
        # ChatCompletionìœ¼ë¡œ êµì • ê²°ê³¼ ìƒì„±
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful English teacher."},
                {"role": "user", "content": prompt}
            ]
        )
        reply = response.choices[0].message.content
        await update.message.reply_text(reply)

        # ìŒì„± ì‘ë‹µ ìƒì„±
        speech = openai.audio.speech.create(
            model="tts-1",
            voice="nova",
            input=reply
        )
        tts_path = "response.mp3"
        with open(tts_path, "wb") as f:
            f.write(speech.content)

        await update.message.reply_voice(voice=open(tts_path, "rb"))

    except Exception as e:
        await update.message.reply_text(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# í…ìŠ¤íŠ¸ ë©”ì‹œì§€ í•¸ë“¤ëŸ¬
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await correct_english_and_respond(update.message.text, update)

# ìŒì„± ë©”ì‹œì§€ í•¸ë“¤ëŸ¬
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    file = await context.bot.get_file(update.message.voice.file_id)
    ogg_path = "voice.ogg"
    mp3_path = "voice.mp3"
    await file.download_to_drive(ogg_path)
    AudioSegment.from_ogg(ogg_path).export(mp3_path, format="mp3")

    with open(mp3_path, "rb") as f:
        transcript = openai.audio.transcriptions.create(
            model="whisper-1",
            file=f
        )

    user_text = transcript.text
    await update.message.reply_text(f"ğŸ—£ ì¸ì‹ëœ ë¬¸ì¥: {user_text}")
    await correct_english_and_respond(user_text, update)

if __name__ == "__main__":
    app = ApplicationBuilder().token(os.getenv("TELEGRAM_TOKEN")).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))

    print("âœ… Bot is running with GPT + Voice")
    app.run_polling()
